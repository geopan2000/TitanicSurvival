{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Apply the mapping to both the training and test data\n",
        "def map_ordinal_features(df, mappings):\n",
        "    for feature, mapping in mappings.items():\n",
        "        df[feature] = df[feature].map(mapping)\n",
        "    return df\n",
        "\n",
        "def frequency_encoding(train_df, test_df, column):\n",
        "    # Get the frequency of each category in the train data\n",
        "    freq_map = train_df[column].value_counts(normalize=True).to_dict()\n",
        "\n",
        "    # Map the frequencies to the train and test data using the same mapping\n",
        "    train_df[column] = train_df[column].map(freq_map)\n",
        "    test_df[column] = test_df[column].map(freq_map)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "def binary_encoding(df, mappings):\n",
        "    for feature, mapping in mappings.items():\n",
        "        df[feature] = df[feature].map(mapping)\n",
        "    return df"
      ],
      "metadata": {
        "id": "pEGO0a05TLkY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Titanic Survival Prediction"
      ],
      "metadata": {
        "id": "EmaWcD5u7CdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/geopan2000/TitanicSurvival.git\n",
        "\n",
        "# Change directory to the cloned repository\n",
        "%cd TitanicSurvival"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi8aXOpR6_ax",
        "outputId": "aeca43e1-9c2a-4b00-cf48-ca153a4dc9cb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TitanicSurvival'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 15 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (15/15), 38.02 KiB | 9.50 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "/content/TitanicSurvival/TitanicSurvival/TitanicSurvival\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DIaqHYf6PqFI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HEOS2uRLdUTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2381dd-b134-4534-ae6b-8ed555a1f581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv('data/train.csv')\n",
        "print(train_data.info())\n",
        "test_data = pd.read_csv('data/test.csv')\n",
        "print(test_data.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-Processing"
      ],
      "metadata": {
        "id": "-axOmu76auqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Age']=train_data['Age'].fillna(train_data['Age'].mean())\n",
        "train_data['Age']=train_data['Age'] / 100\n",
        "\n",
        "test_data['Age']=test_data['Age'].fillna(train_data['Age'].mean())\n",
        "test_data['Age']=test_data['Age'] / 100"
      ],
      "metadata": {
        "id": "aZhRnPedPtVu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply one-hot encoding on train and test data\n",
        "train_data = train_data.dropna(subset=['Embarked'])\n",
        "train_data = pd.get_dummies(train_data, columns=['Embarked'])\n",
        "test_data = pd.get_dummies(test_data, columns=['Embarked'])\n",
        "\n",
        "test_data['Fare']=test_data['Fare'].fillna(test_data['Fare'].mean())\n",
        "\n",
        "train_data.drop('Cabin', axis=1, inplace=True)\n",
        "train_data.drop('Name', axis=1, inplace=True)\n",
        "train_data.drop('Ticket', axis=1, inplace=True)\n",
        "test_data.drop('Cabin', axis=1, inplace=True)\n",
        "test_data.drop('Name', axis=1, inplace=True)\n",
        "test_data.drop('Ticket', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "ZIvrpX70Yk6B"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the 'Sex' column: 'male' to 1 and 'female' to 0\n",
        "train_data['Sex'] = train_data['Sex'].map({'male': 1, 'female': 0})\n",
        "\n",
        "# If you have a test set and want to apply the same transformation\n",
        "test_data['Sex'] = test_data['Sex'].map({'male': 1, 'female': 0})"
      ],
      "metadata": {
        "id": "b9QiiQ_2clPf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.info())\n",
        "\n",
        "print(test_data.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtEPf2DtZRvl",
        "outputId": "affcab03-4851-4625-9f82-8fb4ce483791"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 889 entries, 0 to 890\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  889 non-null    int64  \n",
            " 1   Survived     889 non-null    int64  \n",
            " 2   Pclass       889 non-null    int64  \n",
            " 3   Sex          889 non-null    int64  \n",
            " 4   Age          889 non-null    float64\n",
            " 5   SibSp        889 non-null    int64  \n",
            " 6   Parch        889 non-null    int64  \n",
            " 7   Fare         889 non-null    float64\n",
            " 8   Embarked_C   889 non-null    bool   \n",
            " 9   Embarked_Q   889 non-null    bool   \n",
            " 10  Embarked_S   889 non-null    bool   \n",
            "dtypes: bool(3), float64(2), int64(6)\n",
            "memory usage: 65.1 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 10 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Sex          418 non-null    int64  \n",
            " 3   Age          418 non-null    float64\n",
            " 4   SibSp        418 non-null    int64  \n",
            " 5   Parch        418 non-null    int64  \n",
            " 6   Fare         418 non-null    float64\n",
            " 7   Embarked_C   418 non-null    bool   \n",
            " 8   Embarked_Q   418 non-null    bool   \n",
            " 9   Embarked_S   418 non-null    bool   \n",
            "dtypes: bool(3), float64(2), int64(5)\n",
            "memory usage: 24.2 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = train_data['Survived']\n",
        "train_data.drop('Survived', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "QMtKHWOjct1V"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "!pip install scikit-optimize\n",
        "!pip install shap\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer"
      ],
      "metadata": {
        "id": "somkE1rtfDUk",
        "outputId": "de2f59f9-d771-43e7-ebb8-e1f0872c5e56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-24.9.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.9.0 scikit-optimize-0.10.2\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.46.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.5)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (3.1.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what GPU is available in Google Colab\n",
        "!nvidia-smi\n",
        "\n",
        "# Define parameter search space\n",
        "search_spaces = {\n",
        "    'learning_rate': Real(0.001, 0.5, 'uniform'),\n",
        "    'max_depth': Integer(1, 70),\n",
        "    'n_estimators': Integer(100, 800),\n",
        "}\n",
        "\n",
        "# Initialize the XGBClassifier model with GPU support\n",
        "model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',  # Use for binary classification\n",
        "    tree_method='gpu_hist',  # Use GPU for training\n",
        "    verbosity=2\n",
        ")\n",
        "\n",
        "kf = KFold(n_splits=10)  # 10-fold cross-validation\n",
        "\n",
        "# Using 'accuracy' as the scoring metric (can be changed to roc_auc, f1, etc.)\n",
        "optimizer = BayesSearchCV(\n",
        "    estimator=model,\n",
        "    search_spaces=search_spaces,\n",
        "    n_iter=64,\n",
        "    cv=kf,\n",
        "    scoring='accuracy',  # Use classification accuracy as the scoring metric\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Fit the optimizer using X_train and y_train (classification labels, not log-transformed)\n",
        "optimizer.fit(train_data, target_column)\n",
        "\n",
        "# Get the best model\n",
        "best_model = optimizer.best_estimator_\n",
        "\n",
        "# Get cross-validation results\n",
        "cv_results = optimizer.cv_results_\n",
        "\n",
        "# Print best parameters and mean accuracy\n",
        "mean_accuracy = cv_results['mean_test_score']  # Mean accuracy for each fold\n",
        "\n",
        "print(f\"Best parameters: {optimizer.best_params_}\")\n",
        "print(f\"Mean Cross-validation Accuracy: {mean_accuracy.mean():.4f}\")\n",
        "print(f\"Cross-validation Accuracy for each iteration: {mean_accuracy}\")\n",
        "\n",
        "print(\"Optimization complete. Best XGBoost classifier model saved.\")\n"
      ],
      "metadata": {
        "id": "ukpZVDgZc5bH",
        "outputId": "9b895e0c-5a53-43b6-fc3a-9b7aecb416cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 23 13:08:23 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [13:23:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: OrderedDict([('learning_rate', 0.02141371663804202), ('max_depth', 28), ('n_estimators', 110)])\n",
            "Mean Cross-validation Accuracy: 0.7877\n",
            "Cross-validation Accuracy for each iteration: [0.78855975 0.7862998  0.78628703 0.77846016 0.78516343 0.79642492\n",
            " 0.79304137 0.77056946 0.78854699 0.77506384 0.80879724 0.82228039\n",
            " 0.81778601 0.61756895 0.61756895 0.61756895 0.80203013 0.78854699\n",
            " 0.82114402 0.79980848 0.7862998  0.81666241 0.81892237 0.8020429\n",
            " 0.78628703 0.82000766 0.80542646 0.80430286 0.78965781 0.79530133\n",
            " 0.79980848 0.79756129 0.79867211 0.79530133 0.79864658 0.81103166\n",
            " 0.79304137 0.79753575 0.79643769 0.80429009 0.82005873 0.82340398\n",
            " 0.80655005 0.61756895 0.82226762 0.79867211 0.79191777 0.80656282\n",
            " 0.81553882 0.80094484 0.78965781 0.80091931 0.79868488 0.8020429\n",
            " 0.80431563 0.79867211 0.79980848 0.78516343 0.7840526  0.79081971\n",
            " 0.79193054 0.79979571 0.79306691 0.79193054]\n",
            "Optimization complete. Best XGBoost classifier model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Make predictions using the best model directly on test_data\n",
        "preds = best_model.predict(test_data)\n",
        "\n",
        "# Prepare the output DataFrame\n",
        "output = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': preds})\n",
        "\n",
        "# Remove any duplicate rows by 'PassengerId'\n",
        "output.drop_duplicates(subset='PassengerId', keep='first', inplace=True)\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "output.to_csv('predictions.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to predictions.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "s6ogFgNYjN9_",
        "outputId": "bc9ccaef-6e58-408c-a72d-5c393d994592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [13:33:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [13:33:38] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('predictions.csv')"
      ],
      "metadata": {
        "id": "jYv5L6E-lZmR",
        "outputId": "36bb7847-965a-4175-b0ea-961ed36d5aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_871de602-689b-43c8-89cb-03ee36cccc0c\", \"predictions.csv\", 2839)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}